{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 2 - multi-class iris.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UoA-eResearch/deep-learning-tutorial/blob/master/Exercise%202%20-%20multi-class%20iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPQTvjnTzTqM",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2: The Iris Dataset\n",
        "In this exercise we will create a neural network to classify 3 different types of Iris (Setosa, Versicolor and Virginica) based on their sepal length, sepal width, petal length and petal width.\n",
        "\n",
        "![Irises](http://dataaspirant.com/wp-content/uploads/2017/01/irises.png)\n",
        "\n",
        "This is a multi class classification problem. It is similar to the Pima Indian's binary classification exercise, but with three classes to predict instead of two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6B9pUqCzTqO",
        "colab_type": "text"
      },
      "source": [
        "### Import dependencies\n",
        "Start by importing the dependencies we will need for the project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB8CJHppzTqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0855514c-cc7e-45c3-fb40-a7568400a84f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcA6fnZKzTqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_acc_loss(history):\n",
        "    f, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax1.plot(history.history['loss'])\n",
        "    ax1.plot(history.history['val_loss'])\n",
        "    ax1.set_title('model loss')\n",
        "    ax1.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    # Summarize history of accuracy\n",
        "    ax2.plot(history.history['acc'])\n",
        "    ax2.plot(history.history['val_acc'])\n",
        "    ax2.set_title('model accuracy')\n",
        "    ax2.set_xlabel('epoch')\n",
        "    ax2.legend(['train', 'test'], loc='upper left')\n",
        "    \n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuDTA3s9zTqV",
        "colab_type": "text"
      },
      "source": [
        "### Set seed\n",
        "Set a seed value so that when we repeatedly run our code we will get the same result. Using the same seed is important when you want to compare algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLiwmMNzTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxNqXnJTzTqY",
        "colab_type": "text"
      },
      "source": [
        "### Import data\n",
        "The Iris dataset contains four features from 150 different Iris flowers. The features in the dataset are described below.\n",
        "\n",
        "* Sepal length (cm)\n",
        "* Sepal width (cm)\n",
        "* Petal length (cm)\n",
        "* Petal width (cm)\n",
        "* Class: Iris setosa, Iris versicolor or Iris virginica\n",
        "\n",
        "Sepals are the part of a flower that protect and support the petals. The petals surround the reproductive parts of the flower.\n",
        "\n",
        "![Iris labeled](http://terpconnect.umd.edu/~petersd/666/html/iris_with_labels.jpg)\n",
        "\n",
        "A snapshot of the dataset is illustrated below (not in order).\n",
        "\n",
        "|Sepal Length|Sepal Width|Petal Length|Petal Width|Class|\n",
        "|---|---|---|---|-----------|\n",
        "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
        "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
        "|7.0|3.2|4.7|1.4|Iris-versicolor|\n",
        "|6.4|3.2|4.5|1.5|Iris-versicolor|\n",
        "|6.3|3.3|6.0|2.5|Iris-virginica|\n",
        "|5.8|2.7|5.1|1.9|Iris-virginica|\n",
        "\n",
        "To load this data into memory, use the `np.loadtxt` function. The data type (`dtype`) is set to `str` because our input data is a mix of numbers and strings. This will be dealt with when we split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wYz6SEDzTqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "469639fb-5ad9-433a-c4c7-236a8c13da95"
      },
      "source": [
        "data = np.loadtxt('https://raw.githubusercontent.com/UoA-eResearch/deep-learning-tutorial/master/data/iris.csv?token=AHHIO3VKGHYLCEE6KZT2SRC5BATXM', delimiter=\",\", dtype=str)\n",
        "print(data[:20])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1' '3.5' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.0' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.7' '3.2' '1.3' '0.2' 'Iris-setosa']\n",
            " ['4.6' '3.1' '1.5' '0.2' 'Iris-setosa']\n",
            " ['5.0' '3.6' '1.4' '0.2' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.7' '0.4' 'Iris-setosa']\n",
            " ['4.6' '3.4' '1.4' '0.3' 'Iris-setosa']\n",
            " ['5.0' '3.4' '1.5' '0.2' 'Iris-setosa']\n",
            " ['4.4' '2.9' '1.4' '0.2' 'Iris-setosa']\n",
            " ['4.9' '3.1' '1.5' '0.1' 'Iris-setosa']\n",
            " ['5.4' '3.7' '1.5' '0.2' 'Iris-setosa']\n",
            " ['4.8' '3.4' '1.6' '0.2' 'Iris-setosa']\n",
            " ['4.8' '3.0' '1.4' '0.1' 'Iris-setosa']\n",
            " ['4.3' '3.0' '1.1' '0.1' 'Iris-setosa']\n",
            " ['5.8' '4.0' '1.2' '0.2' 'Iris-setosa']\n",
            " ['5.7' '4.4' '1.5' '0.4' 'Iris-setosa']\n",
            " ['5.4' '3.9' '1.3' '0.4' 'Iris-setosa']\n",
            " ['5.1' '3.5' '1.4' '0.3' 'Iris-setosa']\n",
            " ['5.7' '3.8' '1.7' '0.3' 'Iris-setosa']\n",
            " ['5.1' '3.8' '1.5' '0.3' 'Iris-setosa']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGLO13AQzTqb",
        "colab_type": "text"
      },
      "source": [
        "Separate the data into input (X) and output (y) variables.\n",
        "\n",
        "Note that we convert the input data into floats."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EcR4awzTqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data[:, 0:4].astype(float)\n",
        "y = data[:, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zYDMAbzTqd",
        "colab_type": "text"
      },
      "source": [
        "If you look carefully at the target values, you will notice that they are strings, i.e. 'Iris-setosa', 'Iris-versicolor' and 'Iris-virginica'.\n",
        "\n",
        "Keras needs numbers or matrices to work with, so we will need to reformat the target values.\n",
        "\n",
        "The problem with converting the class values to numbers (e.g. 'Iris-setosa' becomes 0, 'Iris-versicolor' 1 etc) is that it implies that the target values are ordinal. That is, 'Iris-setosa' is somehow less than 'Iris-versicolor'.\n",
        "\n",
        "A better way to represent classes in a multi-class classification problem, is to 'one hot encode' the target values. An example is shown below. A matrix of zeros is generated. Each row corresponds to a sample and each column corresponds to a particular class. A 1 is placed into the column to incidicate the class that it belongs too.\n",
        "\n",
        "|Iris-setosa|Iris-versicolor|Iris-virginica|\n",
        "|---|---|---|\n",
        "|1|0|0|\n",
        "|0|1|0|\n",
        "|0|0|1|\n",
        "\n",
        "One hot encoding is a two step process. First encode the target values (y) into an array of numbers using the `LabelEncoder` from scikit-learn and then one hot encode the numbers with the `np_utils.to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmReXRywzTqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_encoded = LabelEncoder().fit(y).transform(y) # Convert the classes into numbers\n",
        "y_one_hot_encoded = np_utils.to_categorical(y_encoded) # One hot encode the numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6YS0NRVzTqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "402bd4cc-d3b6-42b7-db0b-3ac7c9af4c5b"
      },
      "source": [
        "y_encoded"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQgfvZcfzTqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f3c55201-bda6-4f79-c9f4-3c5491902d38"
      },
      "source": [
        "y_one_hot_encoded[0:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9s47Jx9zTqk",
        "colab_type": "text"
      },
      "source": [
        "Like the previous exercise, use the `train_test_split` function from scikit-learn to split the input and target data into training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdeRm6LzTql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.33, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gp1FcnQzTqn",
        "colab_type": "text"
      },
      "source": [
        "### Create the model\n",
        "The code snippet below creates a very basic neural network model, with three layers: an input layer, a hidden layer and an output layer.\n",
        "\n",
        "The first layer is a fully connected `Dense` layer. We use four neurons in the hidden layer and have 4 input neurons for the 4 features.\n",
        "\n",
        "The last layer has 3 neurons, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG9oXx6dzTqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47a50243-c551-402b-be49-904f8cbef7ad"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=4, activation='relu', kernel_initializer='normal'))\n",
        "model.add(Dense(3, activation='sigmoid', kernel_initializer='normal'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McwgpeyfzTqp",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model\n",
        "We then compile the model. The loss function is set to `categorical_crossentropy` (different from the loss function used in the binary classification exercise) because we are performing multi-class classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F86R20yJzTqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr-3q6CEzTqs",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "Now that we have compiled the model, we can train it with the data we prepared earlier. We are using more epochs but a smaller batch size than the previous exercise.\n",
        "\n",
        "To see the model training history in text, just don't include `verbose=0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ohIS-DzTqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6885
        },
        "outputId": "9918b8d8-0462-4e2c-d670-f26231846494"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 1.0999 - acc: 0.3600 - val_loss: 1.0989 - val_acc: 0.2800\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 0s 316us/step - loss: 1.0974 - acc: 0.5400 - val_loss: 1.0968 - val_acc: 0.6400\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 1.0952 - acc: 0.6800 - val_loss: 1.0942 - val_acc: 0.6400\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 0s 308us/step - loss: 1.0925 - acc: 0.6800 - val_loss: 1.0906 - val_acc: 0.6400\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 1.0886 - acc: 0.6600 - val_loss: 1.0855 - val_acc: 0.6400\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 1.0835 - acc: 0.6800 - val_loss: 1.0795 - val_acc: 0.6400\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 0s 293us/step - loss: 1.0761 - acc: 0.6800 - val_loss: 1.0718 - val_acc: 0.6400\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 0s 317us/step - loss: 1.0666 - acc: 0.6800 - val_loss: 1.0614 - val_acc: 0.6400\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 0s 345us/step - loss: 1.0551 - acc: 0.6800 - val_loss: 1.0493 - val_acc: 0.6400\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 0s 349us/step - loss: 1.0418 - acc: 0.6800 - val_loss: 1.0351 - val_acc: 0.6400\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 0s 331us/step - loss: 1.0254 - acc: 0.6800 - val_loss: 1.0185 - val_acc: 0.6400\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 1.0079 - acc: 0.6800 - val_loss: 1.0012 - val_acc: 0.6400\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.9883 - acc: 0.6800 - val_loss: 0.9816 - val_acc: 0.6400\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.9669 - acc: 0.6800 - val_loss: 0.9609 - val_acc: 0.6400\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 0s 326us/step - loss: 0.9448 - acc: 0.6800 - val_loss: 0.9395 - val_acc: 0.6400\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 0s 326us/step - loss: 0.9207 - acc: 0.6800 - val_loss: 0.9166 - val_acc: 0.6400\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 0s 314us/step - loss: 0.8984 - acc: 0.6800 - val_loss: 0.8957 - val_acc: 0.6400\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 0s 367us/step - loss: 0.8728 - acc: 0.6800 - val_loss: 0.8715 - val_acc: 0.6400\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 0s 363us/step - loss: 0.8493 - acc: 0.6800 - val_loss: 0.8494 - val_acc: 0.6400\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.8250 - acc: 0.6800 - val_loss: 0.8281 - val_acc: 0.6400\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.8015 - acc: 0.6800 - val_loss: 0.8073 - val_acc: 0.6400\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.7781 - acc: 0.6800 - val_loss: 0.7859 - val_acc: 0.6400\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 0s 305us/step - loss: 0.7549 - acc: 0.6800 - val_loss: 0.7649 - val_acc: 0.6400\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.7335 - acc: 0.6800 - val_loss: 0.7460 - val_acc: 0.6400\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 0s 280us/step - loss: 0.7123 - acc: 0.6900 - val_loss: 0.7270 - val_acc: 0.6400\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 0s 296us/step - loss: 0.6920 - acc: 0.6900 - val_loss: 0.7094 - val_acc: 0.6400\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 0s 275us/step - loss: 0.6730 - acc: 0.6900 - val_loss: 0.6925 - val_acc: 0.6600\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 0s 311us/step - loss: 0.6551 - acc: 0.6900 - val_loss: 0.6757 - val_acc: 0.6600\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.6381 - acc: 0.7100 - val_loss: 0.6619 - val_acc: 0.6600\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.6198 - acc: 0.7300 - val_loss: 0.6456 - val_acc: 0.6600\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.6052 - acc: 0.7300 - val_loss: 0.6321 - val_acc: 0.6600\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.5891 - acc: 0.7400 - val_loss: 0.6179 - val_acc: 0.7400\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.5748 - acc: 0.7900 - val_loss: 0.6046 - val_acc: 0.8200\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 0s 310us/step - loss: 0.5610 - acc: 0.8500 - val_loss: 0.5922 - val_acc: 0.8600\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 0s 320us/step - loss: 0.5484 - acc: 0.8900 - val_loss: 0.5796 - val_acc: 0.8600\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.5359 - acc: 0.8900 - val_loss: 0.5689 - val_acc: 0.9200\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 0s 291us/step - loss: 0.5246 - acc: 0.9700 - val_loss: 0.5579 - val_acc: 0.9600\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.5133 - acc: 0.9700 - val_loss: 0.5480 - val_acc: 0.9600\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.5030 - acc: 0.9700 - val_loss: 0.5382 - val_acc: 0.9600\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 0s 291us/step - loss: 0.4928 - acc: 0.9700 - val_loss: 0.5287 - val_acc: 0.9600\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.4841 - acc: 0.9700 - val_loss: 0.5201 - val_acc: 0.9800\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.4741 - acc: 0.9700 - val_loss: 0.5117 - val_acc: 0.9600\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.4667 - acc: 0.9700 - val_loss: 0.5039 - val_acc: 0.9600\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 0s 280us/step - loss: 0.4589 - acc: 0.9600 - val_loss: 0.4954 - val_acc: 1.0000\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 0.4488 - acc: 0.9700 - val_loss: 0.4876 - val_acc: 0.9800\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.4430 - acc: 0.9700 - val_loss: 0.4805 - val_acc: 0.9600\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.4334 - acc: 0.9700 - val_loss: 0.4728 - val_acc: 0.9800\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.4258 - acc: 0.9700 - val_loss: 0.4659 - val_acc: 0.9800\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.4200 - acc: 0.9600 - val_loss: 0.4589 - val_acc: 0.9800\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.4136 - acc: 0.9700 - val_loss: 0.4529 - val_acc: 0.9600\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.4092 - acc: 0.9700 - val_loss: 0.4463 - val_acc: 1.0000\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 0.4018 - acc: 0.9700 - val_loss: 0.4397 - val_acc: 0.9600\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.3941 - acc: 0.9700 - val_loss: 0.4335 - val_acc: 0.9800\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.3863 - acc: 0.9700 - val_loss: 0.4279 - val_acc: 0.9800\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.3827 - acc: 0.9700 - val_loss: 0.4224 - val_acc: 1.0000\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.3749 - acc: 0.9700 - val_loss: 0.4168 - val_acc: 0.9600\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 0s 285us/step - loss: 0.3701 - acc: 0.9700 - val_loss: 0.4111 - val_acc: 0.9600\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.3639 - acc: 0.9700 - val_loss: 0.4061 - val_acc: 0.9800\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.3607 - acc: 0.9600 - val_loss: 0.4007 - val_acc: 1.0000\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.3558 - acc: 0.9700 - val_loss: 0.3963 - val_acc: 0.9600\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.3494 - acc: 0.9700 - val_loss: 0.3908 - val_acc: 0.9800\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.3441 - acc: 0.9700 - val_loss: 0.3858 - val_acc: 0.9800\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.3420 - acc: 0.9700 - val_loss: 0.3815 - val_acc: 0.9800\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 0s 385us/step - loss: 0.3361 - acc: 0.9700 - val_loss: 0.3774 - val_acc: 0.9800\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.3307 - acc: 0.9700 - val_loss: 0.3725 - val_acc: 0.9800\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.3264 - acc: 0.9700 - val_loss: 0.3682 - val_acc: 0.9800\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 0s 282us/step - loss: 0.3220 - acc: 0.9700 - val_loss: 0.3639 - val_acc: 0.9800\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.3187 - acc: 0.9700 - val_loss: 0.3603 - val_acc: 0.9600\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 0s 335us/step - loss: 0.3151 - acc: 0.9700 - val_loss: 0.3558 - val_acc: 0.9800\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 0s 311us/step - loss: 0.3101 - acc: 0.9700 - val_loss: 0.3522 - val_acc: 0.9800\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.3068 - acc: 0.9700 - val_loss: 0.3482 - val_acc: 0.9800\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.3043 - acc: 0.9700 - val_loss: 0.3445 - val_acc: 0.9800\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.2996 - acc: 0.9700 - val_loss: 0.3414 - val_acc: 1.0000\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.2979 - acc: 0.9700 - val_loss: 0.3375 - val_acc: 0.9800\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.2939 - acc: 0.9700 - val_loss: 0.3347 - val_acc: 0.9600\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.2909 - acc: 0.9700 - val_loss: 0.3306 - val_acc: 0.9800\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.2863 - acc: 0.9700 - val_loss: 0.3275 - val_acc: 0.9800\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.2844 - acc: 0.9700 - val_loss: 0.3243 - val_acc: 0.9800\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 0s 276us/step - loss: 0.2817 - acc: 0.9700 - val_loss: 0.3222 - val_acc: 1.0000\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.2773 - acc: 0.9700 - val_loss: 0.3181 - val_acc: 0.9800\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.2749 - acc: 0.9700 - val_loss: 0.3150 - val_acc: 0.9800\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.2709 - acc: 0.9700 - val_loss: 0.3122 - val_acc: 0.9800\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.2696 - acc: 0.9600 - val_loss: 0.3103 - val_acc: 1.0000\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.2656 - acc: 0.9700 - val_loss: 0.3065 - val_acc: 0.9800\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2644 - acc: 0.9700 - val_loss: 0.3036 - val_acc: 0.9800\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 0s 300us/step - loss: 0.2613 - acc: 0.9700 - val_loss: 0.3007 - val_acc: 0.9800\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 0s 337us/step - loss: 0.2579 - acc: 0.9700 - val_loss: 0.2982 - val_acc: 0.9800\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.2558 - acc: 0.9600 - val_loss: 0.2959 - val_acc: 1.0000\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.2531 - acc: 0.9700 - val_loss: 0.2926 - val_acc: 0.9800\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.2507 - acc: 0.9700 - val_loss: 0.2905 - val_acc: 0.9800\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.2495 - acc: 0.9700 - val_loss: 0.2878 - val_acc: 0.9800\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.2461 - acc: 0.9700 - val_loss: 0.2851 - val_acc: 0.9800\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 0s 278us/step - loss: 0.2437 - acc: 0.9600 - val_loss: 0.2832 - val_acc: 1.0000\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.2410 - acc: 0.9600 - val_loss: 0.2803 - val_acc: 0.9800\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 0s 252us/step - loss: 0.2400 - acc: 0.9700 - val_loss: 0.2779 - val_acc: 0.9800\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.2368 - acc: 0.9600 - val_loss: 0.2762 - val_acc: 0.9800\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.2347 - acc: 0.9600 - val_loss: 0.2736 - val_acc: 0.9800\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 0s 366us/step - loss: 0.2339 - acc: 0.9700 - val_loss: 0.2709 - val_acc: 0.9800\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.2303 - acc: 0.9700 - val_loss: 0.2693 - val_acc: 0.9800\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.2293 - acc: 0.9600 - val_loss: 0.2670 - val_acc: 0.9800\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.2274 - acc: 0.9700 - val_loss: 0.2646 - val_acc: 0.9800\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.2258 - acc: 0.9600 - val_loss: 0.2626 - val_acc: 0.9800\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2225 - acc: 0.9600 - val_loss: 0.2622 - val_acc: 1.0000\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.2211 - acc: 0.9600 - val_loss: 0.2586 - val_acc: 0.9800\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.2188 - acc: 0.9700 - val_loss: 0.2566 - val_acc: 0.9800\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 0s 353us/step - loss: 0.2168 - acc: 0.9700 - val_loss: 0.2550 - val_acc: 0.9800\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.2156 - acc: 0.9600 - val_loss: 0.2536 - val_acc: 1.0000\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 0s 266us/step - loss: 0.2137 - acc: 0.9700 - val_loss: 0.2508 - val_acc: 0.9800\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.2134 - acc: 0.9600 - val_loss: 0.2490 - val_acc: 0.9800\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.2110 - acc: 0.9700 - val_loss: 0.2474 - val_acc: 0.9800\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.2089 - acc: 0.9700 - val_loss: 0.2462 - val_acc: 1.0000\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.2080 - acc: 0.9700 - val_loss: 0.2442 - val_acc: 0.9800\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.2084 - acc: 0.9600 - val_loss: 0.2419 - val_acc: 0.9800\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.2034 - acc: 0.9700 - val_loss: 0.2410 - val_acc: 0.9800\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 0s 298us/step - loss: 0.2028 - acc: 0.9700 - val_loss: 0.2391 - val_acc: 0.9800\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.2006 - acc: 0.9700 - val_loss: 0.2373 - val_acc: 0.9800\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.2011 - acc: 0.9700 - val_loss: 0.2356 - val_acc: 0.9800\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.2032 - acc: 0.9700 - val_loss: 0.2365 - val_acc: 1.0000\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 0s 332us/step - loss: 0.1992 - acc: 0.9700 - val_loss: 0.2326 - val_acc: 0.9800\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1967 - acc: 0.9600 - val_loss: 0.2322 - val_acc: 1.0000\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 0s 260us/step - loss: 0.1935 - acc: 0.9700 - val_loss: 0.2293 - val_acc: 0.9800\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 0s 289us/step - loss: 0.1923 - acc: 0.9700 - val_loss: 0.2278 - val_acc: 0.9800\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1914 - acc: 0.9600 - val_loss: 0.2271 - val_acc: 0.9800\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 0s 278us/step - loss: 0.1896 - acc: 0.9600 - val_loss: 0.2249 - val_acc: 0.9800\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.1887 - acc: 0.9700 - val_loss: 0.2239 - val_acc: 0.9800\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 0s 244us/step - loss: 0.1876 - acc: 0.9600 - val_loss: 0.2223 - val_acc: 0.9800\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1857 - acc: 0.9600 - val_loss: 0.2220 - val_acc: 1.0000\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1869 - acc: 0.9800 - val_loss: 0.2209 - val_acc: 1.0000\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 0s 289us/step - loss: 0.1836 - acc: 0.9700 - val_loss: 0.2180 - val_acc: 0.9800\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1850 - acc: 0.9600 - val_loss: 0.2173 - val_acc: 0.9800\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 0s 295us/step - loss: 0.1830 - acc: 0.9600 - val_loss: 0.2154 - val_acc: 0.9800\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 0s 283us/step - loss: 0.1813 - acc: 0.9700 - val_loss: 0.2144 - val_acc: 0.9800\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.1821 - acc: 0.9900 - val_loss: 0.2157 - val_acc: 1.0000\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 0s 239us/step - loss: 0.1772 - acc: 0.9700 - val_loss: 0.2127 - val_acc: 1.0000\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1766 - acc: 0.9600 - val_loss: 0.2107 - val_acc: 0.9800\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 0s 298us/step - loss: 0.1755 - acc: 0.9600 - val_loss: 0.2094 - val_acc: 0.9800\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 0s 271us/step - loss: 0.1748 - acc: 0.9700 - val_loss: 0.2082 - val_acc: 0.9800\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 0s 234us/step - loss: 0.1734 - acc: 0.9600 - val_loss: 0.2077 - val_acc: 0.9800\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 0s 290us/step - loss: 0.1724 - acc: 0.9600 - val_loss: 0.2068 - val_acc: 0.9800\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 0s 273us/step - loss: 0.1724 - acc: 0.9600 - val_loss: 0.2046 - val_acc: 0.9800\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 0s 284us/step - loss: 0.1696 - acc: 0.9700 - val_loss: 0.2044 - val_acc: 0.9800\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1694 - acc: 0.9600 - val_loss: 0.2036 - val_acc: 1.0000\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 0s 249us/step - loss: 0.1689 - acc: 0.9700 - val_loss: 0.2031 - val_acc: 1.0000\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1692 - acc: 0.9600 - val_loss: 0.2002 - val_acc: 0.9800\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 0s 267us/step - loss: 0.1658 - acc: 0.9700 - val_loss: 0.1996 - val_acc: 0.9800\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 0s 264us/step - loss: 0.1657 - acc: 0.9700 - val_loss: 0.1995 - val_acc: 1.0000\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1655 - acc: 0.9600 - val_loss: 0.1981 - val_acc: 0.9800\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1639 - acc: 0.9600 - val_loss: 0.1964 - val_acc: 0.9800\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 0s 277us/step - loss: 0.1629 - acc: 0.9600 - val_loss: 0.1961 - val_acc: 0.9800\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.1630 - acc: 0.9700 - val_loss: 0.1958 - val_acc: 1.0000\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 0s 289us/step - loss: 0.1609 - acc: 0.9700 - val_loss: 0.1932 - val_acc: 0.9800\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 0s 292us/step - loss: 0.1630 - acc: 0.9700 - val_loss: 0.1941 - val_acc: 1.0000\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.1592 - acc: 0.9800 - val_loss: 0.1913 - val_acc: 0.9800\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1587 - acc: 0.9600 - val_loss: 0.1910 - val_acc: 0.9800\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1573 - acc: 0.9600 - val_loss: 0.1901 - val_acc: 0.9800\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1563 - acc: 0.9700 - val_loss: 0.1893 - val_acc: 0.9800\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.1577 - acc: 0.9600 - val_loss: 0.1877 - val_acc: 0.9800\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 0s 315us/step - loss: 0.1556 - acc: 0.9600 - val_loss: 0.1886 - val_acc: 1.0000\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1547 - acc: 0.9700 - val_loss: 0.1870 - val_acc: 1.0000\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 0s 274us/step - loss: 0.1544 - acc: 0.9700 - val_loss: 0.1848 - val_acc: 0.9800\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 0s 336us/step - loss: 0.1528 - acc: 0.9700 - val_loss: 0.1849 - val_acc: 0.9800\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 0s 281us/step - loss: 0.1525 - acc: 0.9600 - val_loss: 0.1839 - val_acc: 0.9800\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 0s 243us/step - loss: 0.1517 - acc: 0.9600 - val_loss: 0.1828 - val_acc: 0.9800\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 0s 242us/step - loss: 0.1504 - acc: 0.9600 - val_loss: 0.1820 - val_acc: 0.9800\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 0s 247us/step - loss: 0.1493 - acc: 0.9600 - val_loss: 0.1808 - val_acc: 0.9800\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.1494 - acc: 0.9700 - val_loss: 0.1814 - val_acc: 1.0000\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 0s 314us/step - loss: 0.1482 - acc: 0.9600 - val_loss: 0.1789 - val_acc: 0.9800\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 0s 250us/step - loss: 0.1483 - acc: 0.9600 - val_loss: 0.1792 - val_acc: 0.9800\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.1465 - acc: 0.9700 - val_loss: 0.1776 - val_acc: 0.9800\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 0s 254us/step - loss: 0.1462 - acc: 0.9600 - val_loss: 0.1769 - val_acc: 0.9800\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1454 - acc: 0.9600 - val_loss: 0.1758 - val_acc: 0.9800\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 0s 301us/step - loss: 0.1463 - acc: 0.9600 - val_loss: 0.1762 - val_acc: 0.9800\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1436 - acc: 0.9600 - val_loss: 0.1747 - val_acc: 0.9800\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1434 - acc: 0.9600 - val_loss: 0.1737 - val_acc: 0.9800\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 0s 246us/step - loss: 0.1423 - acc: 0.9600 - val_loss: 0.1731 - val_acc: 0.9800\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 0s 258us/step - loss: 0.1422 - acc: 0.9600 - val_loss: 0.1721 - val_acc: 0.9800\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 0s 270us/step - loss: 0.1422 - acc: 0.9700 - val_loss: 0.1724 - val_acc: 0.9800\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 0s 269us/step - loss: 0.1424 - acc: 0.9700 - val_loss: 0.1734 - val_acc: 1.0000\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1403 - acc: 0.9600 - val_loss: 0.1699 - val_acc: 0.9800\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 0s 256us/step - loss: 0.1402 - acc: 0.9600 - val_loss: 0.1693 - val_acc: 0.9800\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1394 - acc: 0.9600 - val_loss: 0.1687 - val_acc: 0.9800\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 0s 319us/step - loss: 0.1383 - acc: 0.9700 - val_loss: 0.1687 - val_acc: 0.9800\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 0s 287us/step - loss: 0.1378 - acc: 0.9700 - val_loss: 0.1684 - val_acc: 0.9800\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 0s 261us/step - loss: 0.1371 - acc: 0.9600 - val_loss: 0.1673 - val_acc: 0.9800\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 0s 255us/step - loss: 0.1361 - acc: 0.9700 - val_loss: 0.1667 - val_acc: 0.9800\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 0s 245us/step - loss: 0.1357 - acc: 0.9600 - val_loss: 0.1658 - val_acc: 0.9800\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 0s 259us/step - loss: 0.1354 - acc: 0.9700 - val_loss: 0.1648 - val_acc: 0.9800\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.1345 - acc: 0.9600 - val_loss: 0.1644 - val_acc: 0.9800\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 0s 257us/step - loss: 0.1375 - acc: 0.9700 - val_loss: 0.1645 - val_acc: 0.9800\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1328 - acc: 0.9700 - val_loss: 0.1631 - val_acc: 0.9800\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 0s 336us/step - loss: 0.1328 - acc: 0.9600 - val_loss: 0.1621 - val_acc: 0.9800\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 0s 248us/step - loss: 0.1324 - acc: 0.9600 - val_loss: 0.1619 - val_acc: 0.9800\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 0s 262us/step - loss: 0.1326 - acc: 0.9600 - val_loss: 0.1613 - val_acc: 0.9800\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 0s 301us/step - loss: 0.1317 - acc: 0.9700 - val_loss: 0.1608 - val_acc: 0.9800\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 0s 251us/step - loss: 0.1304 - acc: 0.9600 - val_loss: 0.1598 - val_acc: 0.9800\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 0s 253us/step - loss: 0.1306 - acc: 0.9600 - val_loss: 0.1593 - val_acc: 0.9800\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 0s 309us/step - loss: 0.1300 - acc: 0.9700 - val_loss: 0.1597 - val_acc: 0.9800\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 0s 265us/step - loss: 0.1291 - acc: 0.9700 - val_loss: 0.1579 - val_acc: 0.9800\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 0s 272us/step - loss: 0.1309 - acc: 0.9600 - val_loss: 0.1590 - val_acc: 1.0000\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 0s 263us/step - loss: 0.1288 - acc: 0.9700 - val_loss: 0.1569 - val_acc: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwYPK696zTqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "5bd9a910-aae5-4715-8efd-0d1dfa7edbca"
      },
      "source": [
        "plot_acc_loss(history)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJcCAYAAAA7Pup5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw2wWtw5zTqy",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the model\n",
        "Now that we have trained our model, we can evaluate the performance on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQtZLcOdzTq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "55dc963e-8227-494a-b69f-c7b006a3ed54"
      },
      "source": [
        "scores = model.evaluate(X, y_one_hot_encoded)\n",
        "print(\"\\n\\n{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 0s 40us/step\n",
            "\n",
            "\n",
            "acc: 96.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEnF0buSzTq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCgD2TCKzTq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f6a487b1-fb3c-4a96-8e27-32e3a160cc5f"
      },
      "source": [
        "matrix = metrics.confusion_matrix(y_encoded, y_pred) # (y_true,y_pred)\n",
        "print(matrix)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50  0  0]\n",
            " [ 0 46  4]\n",
            " [ 0  1 49]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhOFX6LUzTrD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "186d9823-b3a6-416e-f9ea-df7c3faefe03"
      },
      "source": [
        "(50+46+49)/(50+46+49+1+4)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vC9cL_a0FJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}